{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sorting_and_cleaning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olkasadova/data-and-python/blob/main/Data_Analysis_Worksheets/Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first.\n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* sort by multiple columns e.g.\n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make\n",
        "* sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly immutable, changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df` *original dataframe, df, will be as it was - unsorted*\n",
        "\n",
        "To split the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score\n",
        "---\n",
        "\n",
        "Read data from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n",
        "**Test output**:  \n",
        "The lowest score (displayed first) is 2.839, Togo  \n",
        "The highest score (displayed last) is 7.587, Switzerland  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH",
        "outputId": "b1b62579-e299-45b0-bf25-1a21e9b31cda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "happiness = pd.read_excel(url)\n",
        "\n",
        "sorted_list_Acs= happiness.sort_values(\"Happiness Score\").head(5)\n",
        "print (\"The lowest score is: \", sorted_list_Acs [\"Country\"], [\"Happiness Score\"])\n",
        "\n",
        "sorted_list_Des= happiness.sort_values(by= [\"Happiness Score\"], ascending = False).head(5)\n",
        "print (\"The highest score is: \", sorted_list_Des [\"Country\"], [\"Happiness Score\"])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lowest score is:  157       Togo\n",
            "156    Burundi\n",
            "155      Syria\n",
            "154      Benin\n",
            "153     Rwanda\n",
            "Name: Country, dtype: object ['Happiness Score']\n",
            "The highest score is:  0    Switzerland\n",
            "1        Iceland\n",
            "2        Denmark\n",
            "3         Norway\n",
            "4         Canada\n",
            "Name: Country, dtype: object ['Happiness Score']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows\n",
        "---\n",
        "\n",
        "1. sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order\n",
        "2. display the first 5 rows of sorted data\n",
        "\n",
        "**Test output**:  \n",
        "Records 122, 127, 147, 100, 96"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-",
        "outputId": "da8a7204-2ec9-41af-af34-7c05dff4c19c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "happiness = pd.read_excel(url)\n",
        "\n",
        "sorted_Economy = happiness.sort_values (by= [ \"Health (Life Expectancy)\", \"Economy (GDP per Capita)\"],ascending = True).head(5)\n",
        "print (sorted_Economy )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Country              Region  Happiness Rank  \\\n",
            "122              Sierra Leone  Sub-Saharan Africa             123   \n",
            "127                  Botswana  Sub-Saharan Africa             128   \n",
            "147  Central African Republic  Sub-Saharan Africa             148   \n",
            "100                 Swaziland  Sub-Saharan Africa             101   \n",
            "96                    Lesotho  Sub-Saharan Africa              97   \n",
            "\n",
            "     Happiness Score  Standard Error  Economy (GDP per Capita)   Family  \\\n",
            "122            4.507         0.07068                   0.33024  0.95571   \n",
            "127            4.332         0.04934                   0.99355  1.10464   \n",
            "147            3.678         0.06112                   0.07850  0.00000   \n",
            "100            4.867         0.08742                   0.71206  1.07284   \n",
            "96             4.898         0.09438                   0.37545  1.04103   \n",
            "\n",
            "     Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
            "122                   0.00000  0.40840                        0.08786   \n",
            "127                   0.04776  0.49495                        0.12474   \n",
            "147                   0.06699  0.48879                        0.08289   \n",
            "100                   0.07566  0.30658                        0.03060   \n",
            "96                    0.07612  0.31767                        0.12504   \n",
            "\n",
            "     Generosity  Dystopia Residual  \n",
            "122     0.21488            2.51009  \n",
            "127     0.10461            1.46181  \n",
            "147     0.23835            2.72230  \n",
            "100     0.18259            2.48676  \n",
            "96      0.16388            2.79832  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order\n",
        "---\n",
        "\n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n",
        "**Test output**:\n",
        "136, 117, 95, 101, 111 Country and Region columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom",
        "outputId": "dad78727-73f1-4b8c-8d49-0d1912543d1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "happiness = pd.read_excel(url)\n",
        "\n",
        "sorted_Trust = happiness.sort_values (by= [ \"Freedom\", \"Trust (Government Corruption)\"],ascending = False).tail(5)\n",
        "print (sorted_Trust )"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Country                           Region  Happiness Rank  \\\n",
            "136                  Angola               Sub-Saharan Africa             137   \n",
            "117                   Sudan               Sub-Saharan Africa             118   \n",
            "95   Bosnia and Herzegovina       Central and Eastern Europe              96   \n",
            "101                  Greece                   Western Europe             102   \n",
            "111                    Iraq  Middle East and Northern Africa             112   \n",
            "\n",
            "     Happiness Score  Standard Error  Economy (GDP per Capita)   Family  \\\n",
            "136            4.033         0.04758                   0.75778  0.86040   \n",
            "117            4.550         0.06740                   0.52107  1.01404   \n",
            "95             4.949         0.06913                   0.83223  0.91916   \n",
            "101            4.857         0.05062                   1.15406  0.92933   \n",
            "111            4.677         0.05232                   0.98549  0.81889   \n",
            "\n",
            "     Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
            "136                   0.16683  0.10384                        0.07122   \n",
            "117                   0.36878  0.10081                        0.14660   \n",
            "95                    0.79081  0.09245                        0.00227   \n",
            "101                   0.88213  0.07699                        0.01397   \n",
            "111                   0.60237  0.00000                        0.13788   \n",
            "\n",
            "     Generosity  Dystopia Residual  \n",
            "136     0.12344            1.94939  \n",
            "117     0.19062            2.20857  \n",
            "95      0.24808            2.06367  \n",
            "101     0.00000            1.80101  \n",
            "111     0.17922            1.95335  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values\n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"Make\"].isnull().values.any()`  \n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values\n",
        "---\n",
        "\n",
        "1. read data from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\n",
        "2. check if any NA values exist in the dataframe and print the result\n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n",
        "\n",
        "**Test output**:\n",
        "True\n",
        ".info shows median_salary, life_satisfaction, recycling_pct, population_size, number_of_jobs, area_size, no_of_houses all less than total rows (1071)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LYkXDNVVc9",
        "outputId": "722b4f79-36de-46e5-e52a-528821fcc33f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "NA_result = df.isnull().values.any()\n",
        "if NA_result == True:\n",
        "  print (\"some data is Null: \", NA_result)\n",
        "else:\n",
        "  print (\"all dataframe has values\", NA_result)\n",
        "\n",
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some data is Null:  True\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1071 entries, 0 to 1070\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   code               1071 non-null   object \n",
            " 1   area               1071 non-null   object \n",
            " 2   date               1071 non-null   object \n",
            " 3   median_salary      1049 non-null   float64\n",
            " 4   life_satisfaction  352 non-null    float64\n",
            " 5   mean_salary        1071 non-null   object \n",
            " 6   recycling_pct      860 non-null    object \n",
            " 7   population_size    1018 non-null   float64\n",
            " 8   number_of_jobs     931 non-null    float64\n",
            " 9   area_size          666 non-null    float64\n",
            " 10  no_of_houses       666 non-null    float64\n",
            " 11  borough_flag       1071 non-null   int64  \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 100.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values\n",
        "---\n",
        "\n",
        "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n",
        "2. remove all NA values across whole dataframe\n",
        "\n",
        "**Test output**:  \n",
        "1.  Row count reduced to 352 rows\n",
        "2.  Row count reduced to 267 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK",
        "outputId": "4bd914fd-d00a-4e19-f2b5-be98edc72cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "#remove rows with NA values for life_satisfaction (use [ ] even if only one column in list)\n",
        "df.dropna (subset = [\"life_satisfaction\"])\n",
        "print (df [\"life_satisfaction\"].count())\n",
        "\n",
        "#remove all NA values across whole dataframe\n",
        "df.dropna()\n",
        "print (df.count())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352\n",
            "code                 1071\n",
            "area                 1071\n",
            "date                 1071\n",
            "median_salary        1049\n",
            "life_satisfaction     352\n",
            "mean_salary          1071\n",
            "recycling_pct         860\n",
            "population_size      1018\n",
            "number_of_jobs        931\n",
            "area_size             666\n",
            "no_of_houses          666\n",
            "borough_flag         1071\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])`\n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries\n",
        "---\n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n",
        "\n",
        "**Test output**:  \n",
        " Dataframe now contains 50 rows all with date 1999-12-*01*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74",
        "outputId": "49153e08-7ddb-4d76-9cca-c37e19470ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.drop_duplicates (subset = [\"area\"])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         code                      area        date  median_salary  \\\n",
              "0   E09000001            city of london  1999-12-01        33020.0   \n",
              "1   E09000002      barking and dagenham  1999-12-01        21480.0   \n",
              "2   E09000003                    barnet  1999-12-01        19568.0   \n",
              "3   E09000004                    bexley  1999-12-01        18621.0   \n",
              "4   E09000005                     brent  1999-12-01        18532.0   \n",
              "5   E09000006                   bromley  1999-12-01        16720.0   \n",
              "6   E09000007                    camden  1999-12-01        23677.0   \n",
              "7   E09000008                   croydon  1999-12-01        19563.0   \n",
              "8   E09000009                    ealing  1999-12-01        20580.0   \n",
              "9   E09000010                   enfield  1999-12-01        19289.0   \n",
              "10  E09000011                 greenwich  1999-12-01        21236.0   \n",
              "11  E09000012                   hackney  1999-12-01        23249.0   \n",
              "12  E09000013    hammersmith and fulham  1999-12-01        25000.0   \n",
              "13  E09000014                  haringey  1999-12-01        18783.0   \n",
              "14  E09000015                    harrow  1999-12-01        20596.0   \n",
              "15  E09000016                  havering  1999-12-01        17165.0   \n",
              "16  E09000017                hillingdon  1999-12-01        24002.0   \n",
              "17  E09000018                  hounslow  1999-12-01        20155.0   \n",
              "18  E09000019                 islington  1999-12-01        25113.0   \n",
              "19  E09000020    kensington and chelsea  1999-12-01        20646.0   \n",
              "20  E09000021      kingston upon thames  1999-12-01        19302.0   \n",
              "21  E09000022                   lambeth  1999-12-01        23151.0   \n",
              "22  E09000023                  lewisham  1999-12-01        20580.0   \n",
              "23  E09000024                    merton  1999-12-01        18962.0   \n",
              "24  E09000025                    newham  1999-12-01        18862.0   \n",
              "25  E09000026                 redbridge  1999-12-01        19580.0   \n",
              "26  E09000027      richmond upon thames  1999-12-01        22321.0   \n",
              "27  E09000028                 southwark  1999-12-01        22784.0   \n",
              "28  E09000029                    sutton  1999-12-01        19582.0   \n",
              "29  E09000030             tower hamlets  1999-12-01        26376.0   \n",
              "30  E09000031            waltham forest  1999-12-01        18547.0   \n",
              "31  E09000032                wandsworth  1999-12-01        21321.0   \n",
              "32  E09000033               westminster  1999-12-01        24447.0   \n",
              "33  E12000001                north east  1999-12-01        16282.0   \n",
              "34  E12000002                north west  1999-12-01        16977.0   \n",
              "35  E12000003  yorkshire and the humber  1999-12-01        16527.0   \n",
              "36  E12000004             east midlands  1999-12-01        16392.0   \n",
              "37  E12000005             west midlands  1999-12-01        17000.0   \n",
              "38  E12000006                      east  1999-12-01        18000.0   \n",
              "39  E12000007                    london  1999-12-01        22487.0   \n",
              "40  E12000008                south east  1999-12-01        18737.0   \n",
              "41  E12000009                south west  1999-12-01        16727.0   \n",
              "42  E13000001              inner london  1999-12-01            NaN   \n",
              "43  E13000002              outer london  1999-12-01            NaN   \n",
              "44  E92000001                   england  1999-12-01        17939.0   \n",
              "45  K02000001            united kingdom  1999-12-01        17803.0   \n",
              "46  K03000001             great britain  1999-12-01        17866.0   \n",
              "47  K04000001         england and wales  1999-12-01        17974.0   \n",
              "48  N92000002          northern ireland  1999-12-01        15798.0   \n",
              "49  S92000003                  scotland  1999-12-01        16914.0   \n",
              "50  W92000004                     wales  1999-12-01        16457.0   \n",
              "\n",
              "    life_satisfaction mean_salary recycling_pct  population_size  \\\n",
              "0                 NaN       48922             0           6581.0   \n",
              "1                 NaN       23620             3         162444.0   \n",
              "2                 NaN       23128             8         313469.0   \n",
              "3                 NaN       21386            18         217458.0   \n",
              "4                 NaN       20911             6         260317.0   \n",
              "5                 NaN       21293            13         294902.0   \n",
              "6                 NaN       30249            13         190003.0   \n",
              "7                 NaN       22205            13         332066.0   \n",
              "8                 NaN       25046            12         302252.0   \n",
              "9                 NaN       21006             9         272731.0   \n",
              "10                NaN       22263             4         212168.0   \n",
              "11                NaN       39629             2         199087.0   \n",
              "12                NaN       28555             7         160634.0   \n",
              "13                NaN       21683             5         218559.0   \n",
              "14                NaN       22824            10         207909.0   \n",
              "15                NaN       18786             8         225712.0   \n",
              "16                NaN       28854            11         245053.0   \n",
              "17                NaN       24602            14         214298.0   \n",
              "18                NaN       34180             2         175717.0   \n",
              "19                NaN       28074            13         147678.0   \n",
              "20                NaN       22967            18         146003.0   \n",
              "21                NaN       27930             8         266817.0   \n",
              "22                NaN       23283             4         250310.0   \n",
              "23                NaN       21867            11         185062.0   \n",
              "24                NaN       20580             3         240517.0   \n",
              "25                NaN       22087             8         238138.0   \n",
              "26                NaN       25832            na         172782.0   \n",
              "27                NaN       26994             3         247853.0   \n",
              "28                NaN       22725            27         179375.0   \n",
              "29                NaN       37524             3         193507.0   \n",
              "30                NaN       19888             9         221057.0   \n",
              "31                NaN       24707             7         264220.0   \n",
              "32                NaN       36167             7         189233.0   \n",
              "33                NaN       18351             5        2550314.0   \n",
              "34                NaN       19609             7        6773115.0   \n",
              "35                NaN       18977             7        4956325.0   \n",
              "36                NaN       18864            11        4152443.0   \n",
              "37                NaN       19686             9        5271959.0   \n",
              "38                NaN       20866            14        5338722.0   \n",
              "39                NaN       29640             9        7153912.0   \n",
              "40                NaN       22361            15        7955124.0   \n",
              "41                NaN       19203            14        4880958.0   \n",
              "42                NaN           -           NaN        2750716.0   \n",
              "43                NaN           -           NaN        4403196.0   \n",
              "44                NaN       21561            10       49032872.0   \n",
              "45                NaN       21314           NaN       58684427.0   \n",
              "46                NaN       21379           NaN       57005421.0   \n",
              "47                NaN       21549           NaN       51933471.0   \n",
              "48                NaN       19093           NaN        1679006.0   \n",
              "49                NaN       19667           NaN        5071950.0   \n",
              "50                NaN       18486           NaN        2900599.0   \n",
              "\n",
              "    number_of_jobs  area_size  no_of_houses  borough_flag  \n",
              "0              NaN        NaN           NaN             1  \n",
              "1              NaN        NaN           NaN             1  \n",
              "2              NaN        NaN           NaN             1  \n",
              "3              NaN        NaN           NaN             1  \n",
              "4              NaN        NaN           NaN             1  \n",
              "5              NaN        NaN           NaN             1  \n",
              "6              NaN        NaN           NaN             1  \n",
              "7              NaN        NaN           NaN             1  \n",
              "8              NaN        NaN           NaN             1  \n",
              "9              NaN        NaN           NaN             1  \n",
              "10             NaN        NaN           NaN             1  \n",
              "11             NaN        NaN           NaN             1  \n",
              "12             NaN        NaN           NaN             1  \n",
              "13             NaN        NaN           NaN             1  \n",
              "14             NaN        NaN           NaN             1  \n",
              "15             NaN        NaN           NaN             1  \n",
              "16             NaN        NaN           NaN             1  \n",
              "17             NaN        NaN           NaN             1  \n",
              "18             NaN        NaN           NaN             1  \n",
              "19             NaN        NaN           NaN             1  \n",
              "20             NaN        NaN           NaN             1  \n",
              "21             NaN        NaN           NaN             1  \n",
              "22             NaN        NaN           NaN             1  \n",
              "23             NaN        NaN           NaN             1  \n",
              "24             NaN        NaN           NaN             1  \n",
              "25             NaN        NaN           NaN             1  \n",
              "26             NaN        NaN           NaN             1  \n",
              "27             NaN        NaN           NaN             1  \n",
              "28             NaN        NaN           NaN             1  \n",
              "29             NaN        NaN           NaN             1  \n",
              "30             NaN        NaN           NaN             1  \n",
              "31             NaN        NaN           NaN             1  \n",
              "32             NaN        NaN           NaN             1  \n",
              "33             NaN        NaN           NaN             0  \n",
              "34             NaN        NaN           NaN             0  \n",
              "35             NaN        NaN           NaN             0  \n",
              "36             NaN        NaN           NaN             0  \n",
              "37             NaN        NaN           NaN             0  \n",
              "38             NaN        NaN           NaN             0  \n",
              "39             NaN        NaN           NaN             0  \n",
              "40             NaN        NaN           NaN             0  \n",
              "41             NaN        NaN           NaN             0  \n",
              "42             NaN        NaN           NaN             0  \n",
              "43             NaN        NaN           NaN             0  \n",
              "44             NaN        NaN           NaN             0  \n",
              "45             NaN        NaN           NaN             0  \n",
              "46             NaN        NaN           NaN             0  \n",
              "47             NaN        NaN           NaN             0  \n",
              "48             NaN        NaN           NaN             0  \n",
              "49             NaN        NaN           NaN             0  \n",
              "50             NaN        NaN           NaN             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c606f11d-00c2-491d-8337-653808c82924\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>area</th>\n",
              "      <th>date</th>\n",
              "      <th>median_salary</th>\n",
              "      <th>life_satisfaction</th>\n",
              "      <th>mean_salary</th>\n",
              "      <th>recycling_pct</th>\n",
              "      <th>population_size</th>\n",
              "      <th>number_of_jobs</th>\n",
              "      <th>area_size</th>\n",
              "      <th>no_of_houses</th>\n",
              "      <th>borough_flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E09000001</td>\n",
              "      <td>city of london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>33020.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48922</td>\n",
              "      <td>0</td>\n",
              "      <td>6581.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E09000002</td>\n",
              "      <td>barking and dagenham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>21480.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23620</td>\n",
              "      <td>3</td>\n",
              "      <td>162444.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E09000003</td>\n",
              "      <td>barnet</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19568.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23128</td>\n",
              "      <td>8</td>\n",
              "      <td>313469.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E09000004</td>\n",
              "      <td>bexley</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18621.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21386</td>\n",
              "      <td>18</td>\n",
              "      <td>217458.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E09000005</td>\n",
              "      <td>brent</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18532.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20911</td>\n",
              "      <td>6</td>\n",
              "      <td>260317.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>E09000006</td>\n",
              "      <td>bromley</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16720.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21293</td>\n",
              "      <td>13</td>\n",
              "      <td>294902.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>E09000007</td>\n",
              "      <td>camden</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>23677.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30249</td>\n",
              "      <td>13</td>\n",
              "      <td>190003.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>E09000008</td>\n",
              "      <td>croydon</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19563.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22205</td>\n",
              "      <td>13</td>\n",
              "      <td>332066.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>E09000009</td>\n",
              "      <td>ealing</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20580.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25046</td>\n",
              "      <td>12</td>\n",
              "      <td>302252.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>E09000010</td>\n",
              "      <td>enfield</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19289.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21006</td>\n",
              "      <td>9</td>\n",
              "      <td>272731.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>E09000011</td>\n",
              "      <td>greenwich</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>21236.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22263</td>\n",
              "      <td>4</td>\n",
              "      <td>212168.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>E09000012</td>\n",
              "      <td>hackney</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>23249.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39629</td>\n",
              "      <td>2</td>\n",
              "      <td>199087.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>E09000013</td>\n",
              "      <td>hammersmith and fulham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>25000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28555</td>\n",
              "      <td>7</td>\n",
              "      <td>160634.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>E09000014</td>\n",
              "      <td>haringey</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18783.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21683</td>\n",
              "      <td>5</td>\n",
              "      <td>218559.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>E09000015</td>\n",
              "      <td>harrow</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20596.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22824</td>\n",
              "      <td>10</td>\n",
              "      <td>207909.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>E09000016</td>\n",
              "      <td>havering</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17165.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18786</td>\n",
              "      <td>8</td>\n",
              "      <td>225712.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>E09000017</td>\n",
              "      <td>hillingdon</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>24002.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28854</td>\n",
              "      <td>11</td>\n",
              "      <td>245053.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>E09000018</td>\n",
              "      <td>hounslow</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20155.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24602</td>\n",
              "      <td>14</td>\n",
              "      <td>214298.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>E09000019</td>\n",
              "      <td>islington</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>25113.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34180</td>\n",
              "      <td>2</td>\n",
              "      <td>175717.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>E09000020</td>\n",
              "      <td>kensington and chelsea</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20646.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28074</td>\n",
              "      <td>13</td>\n",
              "      <td>147678.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>E09000021</td>\n",
              "      <td>kingston upon thames</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19302.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22967</td>\n",
              "      <td>18</td>\n",
              "      <td>146003.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>E09000022</td>\n",
              "      <td>lambeth</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>23151.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27930</td>\n",
              "      <td>8</td>\n",
              "      <td>266817.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>E09000023</td>\n",
              "      <td>lewisham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>20580.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23283</td>\n",
              "      <td>4</td>\n",
              "      <td>250310.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>E09000024</td>\n",
              "      <td>merton</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18962.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21867</td>\n",
              "      <td>11</td>\n",
              "      <td>185062.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>E09000025</td>\n",
              "      <td>newham</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18862.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20580</td>\n",
              "      <td>3</td>\n",
              "      <td>240517.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>E09000026</td>\n",
              "      <td>redbridge</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19580.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22087</td>\n",
              "      <td>8</td>\n",
              "      <td>238138.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>E09000027</td>\n",
              "      <td>richmond upon thames</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>22321.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25832</td>\n",
              "      <td>na</td>\n",
              "      <td>172782.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>E09000028</td>\n",
              "      <td>southwark</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>22784.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26994</td>\n",
              "      <td>3</td>\n",
              "      <td>247853.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>E09000029</td>\n",
              "      <td>sutton</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>19582.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22725</td>\n",
              "      <td>27</td>\n",
              "      <td>179375.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>E09000030</td>\n",
              "      <td>tower hamlets</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>26376.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37524</td>\n",
              "      <td>3</td>\n",
              "      <td>193507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>E09000031</td>\n",
              "      <td>waltham forest</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18547.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19888</td>\n",
              "      <td>9</td>\n",
              "      <td>221057.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>E09000032</td>\n",
              "      <td>wandsworth</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>21321.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24707</td>\n",
              "      <td>7</td>\n",
              "      <td>264220.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>E09000033</td>\n",
              "      <td>westminster</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>24447.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36167</td>\n",
              "      <td>7</td>\n",
              "      <td>189233.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>E12000001</td>\n",
              "      <td>north east</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16282.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18351</td>\n",
              "      <td>5</td>\n",
              "      <td>2550314.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>E12000002</td>\n",
              "      <td>north west</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16977.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19609</td>\n",
              "      <td>7</td>\n",
              "      <td>6773115.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>E12000003</td>\n",
              "      <td>yorkshire and the humber</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16527.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18977</td>\n",
              "      <td>7</td>\n",
              "      <td>4956325.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>E12000004</td>\n",
              "      <td>east midlands</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16392.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18864</td>\n",
              "      <td>11</td>\n",
              "      <td>4152443.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>E12000005</td>\n",
              "      <td>west midlands</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19686</td>\n",
              "      <td>9</td>\n",
              "      <td>5271959.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>E12000006</td>\n",
              "      <td>east</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20866</td>\n",
              "      <td>14</td>\n",
              "      <td>5338722.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>E12000007</td>\n",
              "      <td>london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>22487.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29640</td>\n",
              "      <td>9</td>\n",
              "      <td>7153912.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>E12000008</td>\n",
              "      <td>south east</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>18737.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22361</td>\n",
              "      <td>15</td>\n",
              "      <td>7955124.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>E12000009</td>\n",
              "      <td>south west</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16727.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19203</td>\n",
              "      <td>14</td>\n",
              "      <td>4880958.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>E13000001</td>\n",
              "      <td>inner london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2750716.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>E13000002</td>\n",
              "      <td>outer london</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4403196.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>E92000001</td>\n",
              "      <td>england</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17939.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21561</td>\n",
              "      <td>10</td>\n",
              "      <td>49032872.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>K02000001</td>\n",
              "      <td>united kingdom</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17803.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21314</td>\n",
              "      <td>NaN</td>\n",
              "      <td>58684427.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>K03000001</td>\n",
              "      <td>great britain</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17866.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21379</td>\n",
              "      <td>NaN</td>\n",
              "      <td>57005421.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>K04000001</td>\n",
              "      <td>england and wales</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>17974.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21549</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51933471.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>N92000002</td>\n",
              "      <td>northern ireland</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>15798.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19093</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1679006.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>S92000003</td>\n",
              "      <td>scotland</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16914.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5071950.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>W92000004</td>\n",
              "      <td>wales</td>\n",
              "      <td>1999-12-01</td>\n",
              "      <td>16457.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2900599.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c606f11d-00c2-491d-8337-653808c82924')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c606f11d-00c2-491d-8337-653808c82924 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c606f11d-00c2-491d-8337-653808c82924');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-426342e1-a0b2-4cfc-980c-9bd4b988eb12\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-426342e1-a0b2-4cfc-980c-9bd4b988eb12')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-426342e1-a0b2-4cfc-980c-9bd4b988eb12 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ_tQG_3WBXn"
      },
      "source": [
        "# Normalising Data  \n",
        "When we normalise data, we remodel a numeric column in a dataframe to be on a standard scale (e.g. 0 or 1).   \n",
        "\n",
        "For example if we had a column of BMI scores, we could normalise that column so that all scores greater than or equal to 25 were recoded to the value 1 (bad) and all scores less than 25 were recoded to 0 (good).  \n",
        "\n",
        "To normalise we need to:\n",
        "*   write a function, with the dataframe as a parameter, which will look at each row in dataframe column and return either a value in the normalised scale (e.g. 0,1 or 1,2,3,4) depending on that value.\n",
        "\n",
        "For example:  \n",
        "```\n",
        "def normalise_bmi(df):\n",
        "  if df['bmi'] >= 25:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df[\"bmi\"] = df.apply(normalise_bmi, axis=1)\n",
        "```\n",
        "This code reassigns the values in the column \"bmi\" by sending each row one after the other to the normalise_bmi function, which will check the value in the \"bmi\" column and return either 0 or 1 depending on the value in the \"bmi\" column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8KPmy2_NVh1"
      },
      "source": [
        "### Exercise 7 - normalise data set\n",
        "---\n",
        "\n",
        "Create a function called **normalise_income(df)** that will return the values 1, 2 or 3 to represent low income, middle income and high income.  If the value in `df['median_salary']` is less than 27441 (the median), return 1, otherwise if it is less than 30932 (the upper quartile) return 2 and otherwise return 3.\n",
        "\n",
        "Apply the normalise_income(df) function to the `median_salary` column.\n",
        "\n",
        "*NOTE:  this operation will change the original dataframe so if you run it twice, everything in the median_salary column will change to 1 (as it had already been reduced to 1, 2 or 3 - if this happens, run the code in Exercise 4 again to get the original data again from the file.*\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['median_salary'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktylpCl7QjGJ",
        "outputId": "a40b8a04-ffce-4287-e265-46cccdea385a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "def normalise_income(df):\n",
        "  if df[\"median_salary\"] <= 27441:\n",
        "    return 1\n",
        "  elif df [\"median_salary\"] <= 30932:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "\n",
        "df [\"median_salary\"] = df.apply (normalise_income, axis=1)\n",
        "print (df[\"median_salary\"])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       3\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "1066    2\n",
            "1067    2\n",
            "1068    1\n",
            "1069    2\n",
            "1070    2\n",
            "Name: median_salary, Length: 1071, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCrIEyMjSYTI"
      },
      "source": [
        "### Exercise 8 - normalise the number of jobs column\n",
        "---\n",
        "\n",
        "Using what you have learnt from Exercise 7:  \n",
        "*  use `df.describe()` to find the median, upper quartile and maximum for the number_of_jobs column  \n",
        "*  create a function called **normalise_jobs(df)** that will return 1 if the `number_of_jobs` is below the median, 2 if the `number_of_jobs` is below the upper quartile or 3 otherwise.\n",
        "*  normalise the `number_of_jobs` column by applying the function `normalise_jobs`.\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['number_of_jobs'] will be 3 and the minimum value will be 1  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giYXovr-T7TB",
        "outputId": "9f5b4e94-75d5-4f79-b0ea-18835b3684c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.describe()\n",
        "\n",
        "def normalise_jobsNo (df):\n",
        "  if df [\"number_of_jobs\"] <= 3188000:\n",
        "    return 1\n",
        "  elif df [\"number_of_jobs\"] <= 22170000:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "df [\"number_of_jobs\"] = df.apply (normalise_jobsNo, axis=1)\n",
        "print (df [\"number_of_jobs\"])\n",
        "\n",
        "print (df [\"number_of_jobs\"].max(), df [\"number_of_jobs\"].min())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       3\n",
            "1       3\n",
            "2       3\n",
            "3       3\n",
            "4       3\n",
            "       ..\n",
            "1066    3\n",
            "1067    3\n",
            "1068    3\n",
            "1069    3\n",
            "1070    3\n",
            "Name: number_of_jobs, Length: 1071, dtype: int64\n",
            "3 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-akqnUbYVblH"
      },
      "source": [
        "## Exercise 9 - normalise into a new column\n",
        "---\n",
        "\n",
        "Create a new function and code to normalise the `no_of_houses` column BUT this time, instead of assigning the result to `df['no_of_houses']` assign it to a new column called `df['housing_volume']`\n",
        "\n",
        "**Test output**:  \n",
        "The maximum value of the column df['housing_volume'] will be 3 and the minimum value will be 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnQsE4znV6nD",
        "outputId": "d26be517-6df7-4cad-8d22-e23f780f5aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.describe()\n",
        "\n",
        "def nornalize_houses (df):\n",
        "  if df [\"no_of_houses\"] <= 8814000:\n",
        "    return 1\n",
        "  elif df [\"no_of_houses\"] <= 12620000:\n",
        "    return 2\n",
        "  else:\n",
        "    return 3\n",
        "df [\"housing_volume\"] = df.apply (normalise_jobsNo, axis=1)\n",
        "print (df [\"housing_volume\"])\n",
        "\n",
        "print (df [\"housing_volume\"].max(), df [\"housing_volume\"].min())\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       3\n",
            "1       3\n",
            "2       3\n",
            "3       3\n",
            "4       3\n",
            "       ..\n",
            "1066    3\n",
            "1067    3\n",
            "1068    3\n",
            "1069    3\n",
            "1070    3\n",
            "Name: housing_volume, Length: 1071, dtype: int64\n",
            "3 1\n",
            "           code                      area        date  median_salary  \\\n",
            "1021  E09000002      barking and dagenham  2019-12-01        28738.0   \n",
            "1022  E09000003                    barnet  2019-12-01        31624.0   \n",
            "1023  E09000004                    bexley  2019-12-01        31642.0   \n",
            "1024  E09000005                     brent  2019-12-01        31739.0   \n",
            "1025  E09000006                   bromley  2019-12-01            NaN   \n",
            "1026  E09000007                    camden  2019-12-01        40196.0   \n",
            "1027  E09000008                   croydon  2019-12-01        35237.0   \n",
            "1028  E09000009                    ealing  2019-12-01        31021.0   \n",
            "1029  E09000010                   enfield  2019-12-01        28258.0   \n",
            "1030  E09000011                 greenwich  2019-12-01        33081.0   \n",
            "1031  E09000012                   hackney  2019-12-01        35020.0   \n",
            "1032  E09000013    hammersmith and fulham  2019-12-01        37990.0   \n",
            "1033  E09000014                  haringey  2019-12-01        30452.0   \n",
            "1034  E09000015                    harrow  2019-12-01        32809.0   \n",
            "1035  E09000016                  havering  2019-12-01        32321.0   \n",
            "1036  E09000017                hillingdon  2019-12-01        35231.0   \n",
            "1037  E09000018                  hounslow  2019-12-01        36487.0   \n",
            "1038  E09000019                 islington  2019-12-01        41076.0   \n",
            "1039  E09000020    kensington and chelsea  2019-12-01        33000.0   \n",
            "1040  E09000021      kingston upon thames  2019-12-01        32138.0   \n",
            "1041  E09000022                   lambeth  2019-12-01        36825.0   \n",
            "1042  E09000023                  lewisham  2019-12-01        32334.0   \n",
            "1043  E09000024                    merton  2019-12-01        31699.0   \n",
            "1044  E09000025                    newham  2019-12-01        33944.0   \n",
            "1045  E09000026                 redbridge  2019-12-01        29108.0   \n",
            "1046  E09000027      richmond upon thames  2019-12-01        35191.0   \n",
            "1047  E09000028                 southwark  2019-12-01        40303.0   \n",
            "1048  E09000029                    sutton  2019-12-01        32947.0   \n",
            "1049  E09000030             tower hamlets  2019-12-01        46142.0   \n",
            "1050  E09000031            waltham forest  2019-12-01        30718.0   \n",
            "1051  E09000032                wandsworth  2019-12-01        34168.0   \n",
            "1052  E09000033               westminster  2019-12-01        43556.0   \n",
            "1053  E12000001                north east  2019-12-01        27187.0   \n",
            "1054  E12000002                north west  2019-12-01        28137.0   \n",
            "1055  E12000003  yorkshire and the humber  2019-12-01        27835.0   \n",
            "1056  E12000004             east midlands  2019-12-01        28000.0   \n",
            "1057  E12000005             west midlands  2019-12-01        28536.0   \n",
            "1058  E12000006                      east  2019-12-01        30345.0   \n",
            "1059  E12000007                    london  2019-12-01        38992.0   \n",
            "1060  E12000008                south east  2019-12-01        32120.0   \n",
            "1061  E12000009                south west  2019-12-01        28654.0   \n",
            "1062  E13000001              inner london  2019-12-01            NaN   \n",
            "1063  E13000002              outer london  2019-12-01            NaN   \n",
            "1064  E92000001                   england  2019-12-01        30667.0   \n",
            "1065  K02000001            united kingdom  2019-12-01        30353.0   \n",
            "1066  K03000001             great britain  2019-12-01        30446.0   \n",
            "1067  K04000001         england and wales  2019-12-01        30500.0   \n",
            "1068  N92000002          northern ireland  2019-12-01        27434.0   \n",
            "1069  S92000003                  scotland  2019-12-01        30000.0   \n",
            "1070  W92000004                     wales  2019-12-01        27500.0   \n",
            "\n",
            "      life_satisfaction mean_salary recycling_pct  population_size  \\\n",
            "1021                NaN       32010           NaN              NaN   \n",
            "1022                NaN       37328           NaN              NaN   \n",
            "1023                NaN       33978           NaN              NaN   \n",
            "1024                NaN       36816           NaN              NaN   \n",
            "1025                NaN       37564           NaN              NaN   \n",
            "1026                NaN       49115           NaN              NaN   \n",
            "1027                NaN       38363           NaN              NaN   \n",
            "1028                NaN       36420           NaN              NaN   \n",
            "1029                NaN       36320           NaN              NaN   \n",
            "1030                NaN       36425           NaN              NaN   \n",
            "1031                NaN       42067           NaN              NaN   \n",
            "1032                NaN       48362           NaN              NaN   \n",
            "1033                NaN       35251           NaN              NaN   \n",
            "1034                NaN       37172           NaN              NaN   \n",
            "1035                NaN       37161           NaN              NaN   \n",
            "1036                NaN       41686           NaN              NaN   \n",
            "1037                NaN       50418           NaN              NaN   \n",
            "1038                NaN       53466           NaN              NaN   \n",
            "1039                NaN       41741           NaN              NaN   \n",
            "1040                NaN       37666           NaN              NaN   \n",
            "1041                NaN       48004           NaN              NaN   \n",
            "1042                NaN       36036           NaN              NaN   \n",
            "1043                NaN           #           NaN              NaN   \n",
            "1044                NaN       41592           NaN              NaN   \n",
            "1045                NaN       34096           NaN              NaN   \n",
            "1046                NaN       42092           NaN              NaN   \n",
            "1047                NaN       47811           NaN              NaN   \n",
            "1048                NaN       37392           NaN              NaN   \n",
            "1049                NaN       69434           NaN              NaN   \n",
            "1050                NaN       33119           NaN              NaN   \n",
            "1051                NaN       39617           NaN              NaN   \n",
            "1052                NaN       60010           NaN              NaN   \n",
            "1053                NaN       31852           NaN              NaN   \n",
            "1054                NaN       33479           NaN              NaN   \n",
            "1055                NaN       32653           NaN              NaN   \n",
            "1056                NaN       32639           NaN              NaN   \n",
            "1057                NaN       34247           NaN              NaN   \n",
            "1058                NaN       36143           NaN              NaN   \n",
            "1059                NaN       53100           NaN              NaN   \n",
            "1060                NaN       38715           NaN              NaN   \n",
            "1061                NaN       33543           NaN              NaN   \n",
            "1062                NaN       59987           NaN              NaN   \n",
            "1063                NaN       38614           NaN              NaN   \n",
            "1064                NaN       38206           NaN              NaN   \n",
            "1065                NaN       37428           NaN              NaN   \n",
            "1066                NaN       37603           NaN              NaN   \n",
            "1067                NaN       37865           NaN              NaN   \n",
            "1068                NaN       32083           NaN              NaN   \n",
            "1069                NaN       34916           NaN              NaN   \n",
            "1070                NaN       31251           NaN              NaN   \n",
            "\n",
            "      number_of_jobs  area_size  no_of_houses  borough_flag  housing_volume  \n",
            "1021             NaN        NaN           NaN             1               3  \n",
            "1022             NaN        NaN           NaN             1               3  \n",
            "1023             NaN        NaN           NaN             1               3  \n",
            "1024             NaN        NaN           NaN             1               3  \n",
            "1025             NaN        NaN           NaN             1               3  \n",
            "1026             NaN        NaN           NaN             1               3  \n",
            "1027             NaN        NaN           NaN             1               3  \n",
            "1028             NaN        NaN           NaN             1               3  \n",
            "1029             NaN        NaN           NaN             1               3  \n",
            "1030             NaN        NaN           NaN             1               3  \n",
            "1031             NaN        NaN           NaN             1               3  \n",
            "1032             NaN        NaN           NaN             1               3  \n",
            "1033             NaN        NaN           NaN             1               3  \n",
            "1034             NaN        NaN           NaN             1               3  \n",
            "1035             NaN        NaN           NaN             1               3  \n",
            "1036             NaN        NaN           NaN             1               3  \n",
            "1037             NaN        NaN           NaN             1               3  \n",
            "1038             NaN        NaN           NaN             1               3  \n",
            "1039             NaN        NaN           NaN             1               3  \n",
            "1040             NaN        NaN           NaN             1               3  \n",
            "1041             NaN        NaN           NaN             1               3  \n",
            "1042             NaN        NaN           NaN             1               3  \n",
            "1043             NaN        NaN           NaN             1               3  \n",
            "1044             NaN        NaN           NaN             1               3  \n",
            "1045             NaN        NaN           NaN             1               3  \n",
            "1046             NaN        NaN           NaN             1               3  \n",
            "1047             NaN        NaN           NaN             1               3  \n",
            "1048             NaN        NaN           NaN             1               3  \n",
            "1049             NaN        NaN           NaN             1               3  \n",
            "1050             NaN        NaN           NaN             1               3  \n",
            "1051             NaN        NaN           NaN             1               3  \n",
            "1052             NaN        NaN           NaN             1               3  \n",
            "1053             NaN        NaN           NaN             0               3  \n",
            "1054             NaN        NaN           NaN             0               3  \n",
            "1055             NaN        NaN           NaN             0               3  \n",
            "1056             NaN        NaN           NaN             0               3  \n",
            "1057             NaN        NaN           NaN             0               3  \n",
            "1058             NaN        NaN           NaN             0               3  \n",
            "1059             NaN        NaN           NaN             0               3  \n",
            "1060             NaN        NaN           NaN             0               3  \n",
            "1061             NaN        NaN           NaN             0               3  \n",
            "1062             NaN        NaN           NaN             0               3  \n",
            "1063             NaN        NaN           NaN             0               3  \n",
            "1064             NaN        NaN           NaN             0               3  \n",
            "1065             NaN        NaN           NaN             0               3  \n",
            "1066             NaN        NaN           NaN             0               3  \n",
            "1067             NaN        NaN           NaN             0               3  \n",
            "1068             NaN        NaN           NaN             0               3  \n",
            "1069             NaN        NaN           NaN             0               3  \n",
            "1070             NaN        NaN           NaN             0               3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_FaL31EXHZX"
      },
      "source": [
        "### Exercise 10 - normalise boroughs\n",
        "---\n",
        "\n",
        "Normalise the `area_size` column so that all values below mean are represented as 0 and otherwise are 1.  Assign the output to a new column called `area_size_normalised`.  \n",
        "\n",
        "**Test output**:  \n",
        "`area_size_normalised` column will contain both 0s and 1s.  The position of the first row with value 1 will be 0 and the position of the first row with value 0 will be 102.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doIZ9M0UXkkv",
        "outputId": "cb80ab56-3378-4836-f011-88558f2e3005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.describe()\n",
        "df.dropna (subset = [\"area_size\"])\n",
        "\n",
        "def normalize_area (df):\n",
        "  if df [\"area_size\"] <= 3724000:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "df [\"area_size_normalised\"] = df.apply (normalize_area, axis = 1)\n",
        "\n",
        "print (df.head (10))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        code                  area        date  median_salary  \\\n",
            "0  E09000001        city of london  1999-12-01        33020.0   \n",
            "1  E09000002  barking and dagenham  1999-12-01        21480.0   \n",
            "2  E09000003                barnet  1999-12-01        19568.0   \n",
            "3  E09000004                bexley  1999-12-01        18621.0   \n",
            "4  E09000005                 brent  1999-12-01        18532.0   \n",
            "5  E09000006               bromley  1999-12-01        16720.0   \n",
            "6  E09000007                camden  1999-12-01        23677.0   \n",
            "7  E09000008               croydon  1999-12-01        19563.0   \n",
            "8  E09000009                ealing  1999-12-01        20580.0   \n",
            "9  E09000010               enfield  1999-12-01        19289.0   \n",
            "\n",
            "   life_satisfaction mean_salary recycling_pct  population_size  \\\n",
            "0                NaN       48922             0           6581.0   \n",
            "1                NaN       23620             3         162444.0   \n",
            "2                NaN       23128             8         313469.0   \n",
            "3                NaN       21386            18         217458.0   \n",
            "4                NaN       20911             6         260317.0   \n",
            "5                NaN       21293            13         294902.0   \n",
            "6                NaN       30249            13         190003.0   \n",
            "7                NaN       22205            13         332066.0   \n",
            "8                NaN       25046            12         302252.0   \n",
            "9                NaN       21006             9         272731.0   \n",
            "\n",
            "   number_of_jobs  area_size  no_of_houses  borough_flag  area_size_normalised  \n",
            "0             NaN        NaN           NaN             1                     1  \n",
            "1             NaN        NaN           NaN             1                     1  \n",
            "2             NaN        NaN           NaN             1                     1  \n",
            "3             NaN        NaN           NaN             1                     1  \n",
            "4             NaN        NaN           NaN             1                     1  \n",
            "5             NaN        NaN           NaN             1                     1  \n",
            "6             NaN        NaN           NaN             1                     1  \n",
            "7             NaN        NaN           NaN             1                     1  \n",
            "8             NaN        NaN           NaN             1                     1  \n",
            "9             NaN        NaN           NaN             1                     1  \n"
          ]
        }
      ]
    }
  ]
}